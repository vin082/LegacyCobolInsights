# LLM Provider Configuration
# Options: "openai", "groq", or "google"
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_MODEL=gpt-4o-mini

# Groq Configuration (for cost savings)
# Get your API key from https://console.groq.com
GROQ_API_KEY=gsk_your-groq-api-key-here
GROQ_MODEL=llama-3.1-8b-instant
# Available Groq models: llama-3.1-8b-instant, llama-3.3-70b-versatile, qwen/qwen3-32b, mixtral-8x7b-32768

# Google Gemini Configuration (affordable & powerful)
# Get your API key from https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=AIza-your-google-api-key-here
GEMINI_MODEL=gemini-2.5-flash
# Available Gemini models: gemini-2.0-flash-exp, gemini-2.5-flash, gemini-3-pro-preview

# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-neo4j-password

# LangSmith Configuration (for tracing and evaluations)
# Get your API key from https://smith.langchain.com
LANGCHAIN_TRACING_V2=true
LANGSMITH_API_KEY=lsv2_pt_your-api-key-here
LANGCHAIN_PROJECT=cobol-insights
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# Shared LLM Configuration
LLM_TEMPERATURE=0.0
LLM_MAX_TOKENS=500

# Cache Configuration
CACHE_ENABLED=true
REDIS_ENABLED=false  # Set to true if you have Redis running
REDIS_URL=redis://localhost:6379/0
CACHE_TTL=3600  # Cache time-to-live in seconds (1 hour)

# Processing Configuration
BATCH_SIZE=100
MAX_WORKERS=10
ENABLE_LLM_ENRICHMENT=true

# Application Settings
LOG_LEVEL=INFO
APP_TITLE=COBOL Knowledge Graph System
APP_ICON=üï∏Ô∏è
